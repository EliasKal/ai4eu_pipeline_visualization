{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate distance and add it to the data\n",
    "\n",
    "import haversine as hs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "gps_data = pd.read_csv('sensor_gps.csv')\n",
    "sensor_gps = pd.read_csv('./low_cost_sensors.csv')\n",
    "\n",
    "gps_data = gps_data.iloc[:,1:49]\n",
    "gps_data\n",
    "\n",
    "no2_data = pd.read_csv('./datasets/no2_testset.csv')\n",
    "\n",
    "\n",
    "for i in range(gps_data.shape[1]//2):\n",
    "    lat2 = gps_data.iloc[0,i*2+0]\n",
    "    lon2 = gps_data.iloc[0,i*2+1]\n",
    "    lat1 = sensor_gps.iloc[i,4]\n",
    "    lon1 = sensor_gps.iloc[i,5]\n",
    "    distance = hs.haversine((lat1, lon1), (lat2, lon2))\n",
    "    no2_data.iloc[0,1+i] = distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18140073"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_gps.iloc[0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.indexing._iLocIndexer at 0x7f12b966d778>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_gps = pd.read_csv('./low_cost_sensors.csv')\n",
    "sensor_gps.iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                       7160.000000\n",
       "Ugla skole distance                 2.323791\n",
       "Bispehaugen skole distance          2.943236\n",
       "Singsaker skole distance            2.425800\n",
       "Berg skole distance                 2.397579\n",
       "                                    ...     \n",
       "Sverresborg skole NO2               0.000000\n",
       "Sverresborg skole O3                0.000000\n",
       "Sverresborg skole NO                0.000000\n",
       "Sverresborg skole temperature       9.000000\n",
       "Sverresborg skole humidity         40.000000\n",
       "Name: 2, Length: 192, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no2_data.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data module\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#load required data\n",
    "no2_data = pd.read_csv('./datasets/no2_testset.csv')\n",
    "pm10_data = pd.read_csv('./datasets/pm10_testset.csv')\n",
    "pm25_data = pd.read_csv('./datasets/pm25_testset.csv')\n",
    "gps_data = pd.read_csv('sensor_gps.csv')\n",
    "sensor_gps = pd.read_csv('./low_cost_sensors.csv')\n",
    "\n",
    "gps_data = gps_data.iloc[:,1:49]\n",
    "\n",
    "#counter to get \"random\" values sequentially\n",
    "counter = 0 \n",
    "\n",
    "#get data function\n",
    "def get_row():\n",
    "    row = counter % no2_data.shape[0]\n",
    "    counter +=1\n",
    "\n",
    "    for i in range(gps_data.shape[1]//2):\n",
    "        lat2 = gps_data.iloc[0,i*2+0]\n",
    "        lon2 = gps_data.iloc[0,i*2+1]\n",
    "        lat1 = sensor_gps.iloc[i,4]\n",
    "        lon1 = sensor_gps.iloc[i,5]\n",
    "        distance = hs.haversine((lat1, lon1), (lat2, lon2))\n",
    "        no2_data.iloc[0,1+i] = distance\n",
    "        pm10_data.iloc[0,1+i] = distance\n",
    "        pm25_data.iloc[0,1+i] = distance\n",
    "\n",
    "    no2_input= no2_data.iloc[row,1:].to_numpy()\n",
    "    pm10_input= pm10_data.iloc[row,1:].to_numpy()\n",
    "    pm25_input= pm25_data.iloc[row,1:].to_numpy()    \n",
    "\n",
    "    no2_input = np.ndarray.tobytes(no2_input)\n",
    "    pm10_input = np.ndarray.tobytes(pm10_input)\n",
    "    pm25_input = np.ndarray.tobytes(pm25_input)\n",
    "\n",
    "    return no2_input, pm10_input, pm25_input, no2_data.iloc[row,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_row() missing 1 required positional argument: 'counter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6c51d0b3347e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mno2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_row() missing 1 required positional argument: 'counter'"
     ]
    }
   ],
   "source": [
    "no2, pm10, pm25, test= get_row()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict module\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "\n",
    "no2_model = model = pickle.load(open('no2_model.sav', 'rb'))\n",
    "pm10_model = model = pickle.load(open('pm10_model.sav', 'rb'))\n",
    "pm25_model = model = pickle.load(open('pm25_model.sav', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "def pollutants_prediction(no2_vector, pm10_vector, pm25_vector):\n",
    "    no2_vector = np.frombuffer(no2_vector).reshape(1,-1)\n",
    "    pm10_vector = np.frombuffer(pm10_vector).reshape(1,-1)\n",
    "    pm25_vector = np.frombuffer(pm25_vector).reshape(1,-1)\n",
    "    return (no2_model.predict(no2_vector), pm10_model.predict(pm10_vector), pm25_model.predict(pm25_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_pred, pm10_pred, pm25_pred = pollutants_prediction(no2, pm10, pm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9919943499999997"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm10_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
